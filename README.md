# ESSLLI2021

Welcome to the advanced course on "Analyzing the Cognitive Plausibility of Language Models" taught by Lisa Beinborn (Vrije Universiteit Amsterdam), Nora Hollenstein (University of Copenhagen), and Willem Zuidema (University of Amsterdam). 

In this course, we analyze language models by comparing their internal representations with cognitive signals. We use interpretability methods in order to better understand the information flow in computational language models. 

The course takes place every day from July 26 to July 30 at 4pm. 

For the first day, we invite you to take a moment to think about the following question: “When is a language model cognitively plausible in your opinion?”
You can post your answer in the ESSLLI slack channel (laco-beinborn-hollenstein-zuidema) or send it by e-mail. Please also add one sentence about your background (research discipline). 

Monday: <br>
[Introduction: Cognitive Plausibility of Language Models](https://github.com/beinborn/ESSLLI2021/blob/main/slides/Monday.pdf) (Lisa Beinborn)

Tuesday: <br>
[Lecture: "Cognitive Signals of Language Processing"](https://github.com/beinborn/ESSLLI2021/blob/main/slides/Tuesday.pdf) (Nora Hollenstein)

Wednesday: <br>
[Tutorial: "Predicting Cognitive Signals with Language Models"](https://github.com/beinborn/ESSLLI2021/tree/main/code/tutorial1) (Nora Hollenstein)

Thursday: <br>
[Lecture: "Interpretability of Neural Language Models"](https://github.com/beinborn/ESSLLI2021/blob/main/slides/zuidema21esslli21-handout.pdf) (Willem Zuidema)

Friday: <br>
Tutorial "Interpreting Neural Language Models" (Willem Zuidema) <br>
General Discussion (all lecturers and participants)

