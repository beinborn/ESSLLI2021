# ESSLLI2021

Welcome to the advanced course on "Analyzing the Cognitive Plausibility of Language Models" taught by Lisa Beinborn (Vrije Universiteit Amsterdam), Nora Hollenstein (University of Copenhagen), and Willem Zuidema (University of Amsterdam). 

In this tutorial, we analyze language models by comparing their internal representations with cognitive signals. We use interpretability methods in order to better understand the information flow in computational language models. 

Monday: <br>
Lisa Beinborn: [Introduction: Cognitive Plausibility of Language Models](https://github.com/beinborn/ESSLLI2021/blob/main/slides/Monday.pdf)

Tuesday: <br>
Nora Hollenstein: "Cognitive Signals of Language Processing"

Wednesday: <br>
Nora Hollenstein: "Predicting Cognitive Signals with Language Models"

Thursday: <br>
Willem Zuidema: "Interpretability of Neural Language Models"

Friday: <br>
Willem Zuidema: "Interpreting Neural Language Models with Cognitive Data"

